{"cells":[{"cell_type":"code","execution_count":19,"metadata":{"_cell_guid":"58100c51-88a7-4344-83da-8dc6b96533e6","_uuid":"cf86f7fc-ee5d-4b43-b10a-f7063d27d478","collapsed":false,"execution":{"iopub.execute_input":"2024-10-07T03:37:35.950795Z","iopub.status.busy":"2024-10-07T03:37:35.949984Z","iopub.status.idle":"2024-10-07T03:37:35.957877Z","shell.execute_reply":"2024-10-07T03:37:35.956701Z","shell.execute_reply.started":"2024-10-07T03:37:35.950750Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["from glob import glob\n","import os\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from tqdm import tqdm\n","import random\n","\n","# image stuff\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","###############################\n","# modeling with PyTorch dataset\n","\n","import torch\n","from torch.utils.data import Dataset\n","from torchvision import datasets\n","\n","from torchvision.transforms import ToTensor\n","from torchvision.io import read_image"]},{"cell_type":"markdown","metadata":{"_cell_guid":"046b0aff-ace8-4fe9-baf8-baa4f3042e20","_uuid":"0e9bb69c-39f5-41e1-b8c3-baf78af12031","trusted":true},"source":["# Helpers"]},{"cell_type":"code","execution_count":20,"metadata":{"_cell_guid":"8232a1a4-5118-449f-a193-e7cebe2cc7ff","_kg_hide-input":true,"_uuid":"9a2e87e3-f7d4-40a6-8672-674d3932b7a7","execution":{"iopub.execute_input":"2024-10-07T03:37:35.962629Z","iopub.status.busy":"2024-10-07T03:37:35.962002Z","iopub.status.idle":"2024-10-07T03:37:41.958708Z","shell.execute_reply":"2024-10-07T03:37:41.957664Z","shell.execute_reply.started":"2024-10-07T03:37:35.962594Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1975/1975 [00:05<00:00, 384.23it/s]\n"]}],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import cv2\n","import os\n","from tqdm import tqdm\n","\n","import pydicom\n","import numpy as np\n","import glob\n","\n","df_train_series_descriptions = pd.read_csv(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_series_descriptions.csv\")\n","folder_train_images = os.listdir(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images\")\n","# exclude .DS_store files\n","folder_train_images = list(filter(lambda x: x.find('.DS') == -1, folder_train_images))\n","\n","def get_metadata_object(folder_images, df_series_descriptions):\n","    '''\n","    for intially the train_images folder and train_series_descriptions.csv,\n","    later for the test_images folder and test_series_description.csv\n","    '''\n","    \n","    # a list of tuples like (study_id, study_id's path location)\n","    images_study_id_dirs = [(int(study_id),    # integer the study_id\n","                                   f\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images/{study_id}\") \n","                                  for study_id in folder_images]\n","\n","    # convert the list of tuples into dictionary/metadata\n","    metadata_object = {study_id: {'study_id_folder_path': path, \n","                                    'SeriesInstanceUIDs': [],\n","                                    'SeriesDescriptions': []\n","                                 }\n","                       for study_id, path in images_study_id_dirs\n","                      }\n","\n","    # remove all the .DS files/folders (MacOS) from SeriesInstanceUIDs or series_ids folders\n","    # then put the names for series_ids as well as the corresponding description to metadata\n","    for study_id in tqdm(metadata_object):\n","\n","        # SERIES_ID\n","        # get all series directories/folders inside each study_id directory\n","        series_ids_dirs = os.listdir(metadata_object[study_id]['study_id_folder_path'])\n","        filtered_series_ids_dirs = [int(x) for x in series_ids_dirs if x.find('.DS') == -1]   # integer(series_id)\n","        # put to metadata_object\n","        metadata_object[study_id]['SeriesInstanceUIDs'] = filtered_series_ids_dirs\n","\n","        # SERIES_DESCRIPTIONS\n","        series_desc_df = df_series_descriptions[df_series_descriptions.study_id==study_id][[\"series_id\", \"series_description\"]]\n","        for series_id in metadata_object[study_id]['SeriesInstanceUIDs']:\n","\n","            series_desc_list = series_desc_df[series_desc_df.series_id==series_id].series_description.values\n","\n","            if len(series_desc_list) == 0:\n","                metadata_object[study_id]['SeriesDescriptions'].append(\"\")\n","            else:\n","                metadata_object[study_id]['SeriesDescriptions'].append(series_desc_list[0])\n","                \n","    return metadata_object\n","\n","metadata_object_train = get_metadata_object(folder_train_images, df_train_series_descriptions)\n","\n","\n","\n","\n","\n","def get_series_metadata_object_given_study_id(metadata_object, study_id):\n","    \"\"\"\n","    one study_id can have many series => this func gets all series metadata for this \n","    particular study_id\n","    \"\"\"\n","    \n","    metadata_for_study_id = metadata_object[study_id]\n","    \n","    series_metadata_object_given_study_id = {}\n","\n","    for idx, series_id in enumerate(metadata_for_study_id[\"SeriesInstanceUIDs\"]):\n","\n","        # create bases for the series_images_metadata: each series contains desc and images files\n","        series_metadata_object_given_study_id[series_id] = {'image_series_description': metadata_for_study_id[\"SeriesDescriptions\"][idx], \n","                                                            'image_files': []\n","                                                            }\n","\n","        # glob for patten matching as we want to get image files ending with .dcm\n","        folder_path_study_id = metadata_for_study_id[\"study_id_folder_path\"]\n","        # rmb: \"SeriesInstancesUIDs\" is just a list of images and series_id is the actual series-id\n","        image_files = glob.glob(f\"{folder_path_study_id}/{series_id}/*.dcm\")\n","\n","\n","        # inside image_files, create a metadata for id_image and corresponding dicom readable image file\n","        sorted_image_files = sorted(image_files, key = lambda x: int(x.split('/')[-1].replace('.dcm', '')))\n","\n","        \n","        # iterate through all image files (sorting to make sense, not very necessarily)\n","        for image_file in sorted_image_files:\n","            \n","            dicom_image_id = image_file.split('/')[-1].replace(\".dcm\", '')\n","            dicom_image_read = pydicom.dcmread(image_file)\n","            \n","            # metadata for one image instance\n","            one_image_metadata = {\"SOPInstanceUID\": dicom_image_id,      # id of the dicom image instance file\n","                                  \"dicom_image_file\": dicom_image_read}  # actual read of the dcm instance file\n","\n","            # append this image_metadata to list of image_files\n","            series_metadata_object_given_study_id[series_id][\"image_files\"].append(one_image_metadata)\n","\n","    return series_metadata_object_given_study_id\n","    \n","    \n","    \n","    \n","    \n","    \n","def display_images_given_study_id(metadata_object, study_id): \n","    '''\n","    inside there is another function specifically for this function\n","    '''\n","    \n","    # view images for this study_id = 4003253 for a particular series_description\n","    def display_images(image_files, series_description, max_images_per_row=5):\n","\n","        # grid for display\n","        num_images = len(image_files)\n","        num_rows = (num_images + max_images_per_row - 1) // max_images_per_row  # ceiling division (ignore the remainder, extra)\n","\n","        # subplot grid\n","        fig, axes = plt.subplots(num_rows, max_images_per_row, figsize=(10, 1.5 * num_rows))\n","\n","        # flatten axes for easy looping if there are multiple rows\n","        if num_rows > 1:\n","            axes = axes.flatten()\n","        else:\n","            axes = [axes] # iterable for consistency\n","\n","        # plot each image\n","        for idx, image_file in enumerate(image_files):\n","            ax = axes[idx]\n","            ax.imshow(image_file, cmap='gray') # Assuming grayscale for simplicity, change cmap as needed\n","            ax.axis('off')\n","\n","        # turn off unused subplots\n","        for idx in range(num_images, len(axes)):\n","            axes[idx].axis(\"off\")\n","\n","        fig.suptitle(series_description, fontsize=12)\n","        plt.show()\n","        \n","        \n","        \n","    series_metadata_object = get_series_metadata_object_given_study_id(metadata_object, study_id)\n","    \n","    for series_id in series_metadata_object:\n","\n","        series_description = series_metadata_object[series_id][\"image_series_description\"]\n","\n","        # get the image_files for this particular series_id\n","        image_files = series_metadata_object[series_id][\"image_files\"]\n","\n","        # get the dicom files to a list\n","        dicom_images = []\n","        for image_metadata in image_files:\n","            dicom_image = image_metadata['dicom_image_file'].pixel_array\n","            dicom_images.append(dicom_image)\n","\n","        # display images for each series\n","        display_images(dicom_images, series_description)\n","        \n","        \n","\n","        \n","        \n","        \n","coord_df = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_label_coordinates.csv')\n","# add the columns in coordinates regarding condition+level to match with train_df\n","\n","cols = ['condition', 'level']\n","coord_df['m_condition'] = coord_df[cols].apply(lambda row: ' '.join(row.values.astype(str)).lower(), axis=1)\n","coord_df['m_condition'] = coord_df['m_condition'].str.replace(r'[ /]', '_', regex=True)\n","\n","train_df = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train.csv')\n","\n","\n","\n","def display_images_with_coord(metadata_object, study_id):\n","    '''\n","    again, there is an inner function to display imges\n","    '''\n","    \n","    # this function is for one coord, one image, and one title/description/condition/level)\n","    def display_image_with_coord(center_coord, image_instance_dicom, title):\n","        '''\n","        coord_entry is a particular coord for a particular image \n","        image_meta is the image that specifically in the series, containing SOPInstanceUID and dicom_image_file, i.e. \n","        {2448190387: {'image_series_description': 'Axial T2',\n","                      'image_files': [{'SOPInstanceUID': '1',\n","                                        'dicom_image_file': Dataset.file_meta -------------------------------\n","                                        (0002, 0001) File Meta Informa\n","        '''\n","        radius = 10\n","        color = (255, 0, 0)\n","        thickness = 2\n","\n","        # for what?\n","        image_normalized = cv2.normalize(image_instance_dicom, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n","        # circling\n","        image_circle = cv2.circle(image_normalized.copy(), center_coord, radius, color, thickness)\n","\n","        # convert image from BGR to RGB for correct color display in matplotlib\n","        image_circle = cv2.cvtColor(image_circle, cv2.COLOR_BAYER_BG2BGR)\n","\n","        # display\n","        plt.imshow(image_circle)\n","        plt.axis('off')\n","        plt.title(title)\n","        plt.show()\n","    \n","    \n","    \n","    # example_study_id = 4003253\n","    series_meta =  get_series_metadata_object_given_study_id(metadata_object, study_id) # series_meta all based on given study_id\n","    example_train_df = train_df[train_df.study_id==study_id]\n","    example_coord_entries_df = coord_df[coord_df.study_id==study_id]\n","\n","    for d, coord_entry in example_coord_entries_df.iterrows():\n","\n","        center_coord = (int(coord_entry['x']), int(coord_entry['y']))\n","\n","        # search for the image available for coord in all imgs in series\n","        image_meta_instances_list = series_meta[coord_entry.series_id][\"image_files\"]\n","        # check matching\n","        image_instance_id = coord_entry.instance_number\n","\n","        for image_instance in image_meta_instances_list:\n","\n","            if int(image_instance[\"SOPInstanceUID\"]) == int(image_instance_id):\n","\n","                image_instance_dicom = image_instance[\"dicom_image_file\"].pixel_array\n","\n","                severity = train_df.loc[example_train_df.index[0], coord_entry.m_condition]\n","                title = f'image_instance_id: {image_instance_id} \\n {coord_entry.m_condition} - severity: {severity}'\n","\n","                display_image_with_coord(center_coord, image_instance_dicom, title)"]},{"cell_type":"markdown","metadata":{"_cell_guid":"297f5fce-4e1b-4976-a999-74ec8b3ea8db","_uuid":"826b5a3f-f99b-4f76-abc4-c9de7f7e5ea6","trusted":true},"source":["# 1. Preprocess train.csv & train_label_coordinates.csv"]},{"cell_type":"code","execution_count":21,"metadata":{"_cell_guid":"863aa142-d252-4c32-98b0-f19303d3782c","_uuid":"d933754c-4202-4025-a201-f8a3c6679868","collapsed":false,"execution":{"iopub.execute_input":"2024-10-07T03:37:41.960897Z","iopub.status.busy":"2024-10-07T03:37:41.960569Z","iopub.status.idle":"2024-10-07T03:37:42.041606Z","shell.execute_reply":"2024-10-07T03:37:42.040644Z","shell.execute_reply.started":"2024-10-07T03:37:41.960863Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(1975, 26)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>study_id</th>\n","      <th>spinal_canal_stenosis_l1_l2</th>\n","      <th>spinal_canal_stenosis_l2_l3</th>\n","      <th>spinal_canal_stenosis_l3_l4</th>\n","      <th>spinal_canal_stenosis_l4_l5</th>\n","      <th>spinal_canal_stenosis_l5_s1</th>\n","      <th>left_neural_foraminal_narrowing_l1_l2</th>\n","      <th>left_neural_foraminal_narrowing_l2_l3</th>\n","      <th>left_neural_foraminal_narrowing_l3_l4</th>\n","      <th>left_neural_foraminal_narrowing_l4_l5</th>\n","      <th>...</th>\n","      <th>left_subarticular_stenosis_l1_l2</th>\n","      <th>left_subarticular_stenosis_l2_l3</th>\n","      <th>left_subarticular_stenosis_l3_l4</th>\n","      <th>left_subarticular_stenosis_l4_l5</th>\n","      <th>left_subarticular_stenosis_l5_s1</th>\n","      <th>right_subarticular_stenosis_l1_l2</th>\n","      <th>right_subarticular_stenosis_l2_l3</th>\n","      <th>right_subarticular_stenosis_l3_l4</th>\n","      <th>right_subarticular_stenosis_l4_l5</th>\n","      <th>right_subarticular_stenosis_l5_s1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4003253</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4646740</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7143189</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>8785691</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10728036</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 26 columns</p>\n","</div>"],"text/plain":["   study_id  spinal_canal_stenosis_l1_l2  spinal_canal_stenosis_l2_l3  \\\n","0   4003253                          0.0                          0.0   \n","1   4646740                          0.0                          0.0   \n","2   7143189                          0.0                          0.0   \n","3   8785691                          0.0                          0.0   \n","4  10728036                          0.0                          0.0   \n","\n","   spinal_canal_stenosis_l3_l4  spinal_canal_stenosis_l4_l5  \\\n","0                          0.0                          0.0   \n","1                          1.0                          2.0   \n","2                          0.0                          0.0   \n","3                          0.0                          0.0   \n","4                          0.0                          0.0   \n","\n","   spinal_canal_stenosis_l5_s1  left_neural_foraminal_narrowing_l1_l2  \\\n","0                          0.0                                    0.0   \n","1                          0.0                                    0.0   \n","2                          0.0                                    0.0   \n","3                          0.0                                    0.0   \n","4                          0.0                                    0.0   \n","\n","   left_neural_foraminal_narrowing_l2_l3  \\\n","0                                    0.0   \n","1                                    0.0   \n","2                                    0.0   \n","3                                    0.0   \n","4                                    0.0   \n","\n","   left_neural_foraminal_narrowing_l3_l4  \\\n","0                                    0.0   \n","1                                    0.0   \n","2                                    0.0   \n","3                                    0.0   \n","4                                    0.0   \n","\n","   left_neural_foraminal_narrowing_l4_l5  ...  \\\n","0                                    1.0  ...   \n","1                                    1.0  ...   \n","2                                    0.0  ...   \n","3                                    1.0  ...   \n","4                                    0.0  ...   \n","\n","   left_subarticular_stenosis_l1_l2  left_subarticular_stenosis_l2_l3  \\\n","0                               0.0                               0.0   \n","1                               0.0                               0.0   \n","2                               0.0                               0.0   \n","3                               0.0                               0.0   \n","4                               0.0                               0.0   \n","\n","   left_subarticular_stenosis_l3_l4  left_subarticular_stenosis_l4_l5  \\\n","0                               0.0                               1.0   \n","1                               0.0                               2.0   \n","2                               0.0                               0.0   \n","3                               0.0                               0.0   \n","4                               0.0                               0.0   \n","\n","   left_subarticular_stenosis_l5_s1  right_subarticular_stenosis_l1_l2  \\\n","0                               0.0                                0.0   \n","1                               0.0                                0.0   \n","2                               0.0                                0.0   \n","3                               0.0                                0.0   \n","4                               0.0                                0.0   \n","\n","   right_subarticular_stenosis_l2_l3  right_subarticular_stenosis_l3_l4  \\\n","0                                0.0                                0.0   \n","1                                1.0                                1.0   \n","2                                0.0                                0.0   \n","3                                0.0                                0.0   \n","4                                0.0                                0.0   \n","\n","   right_subarticular_stenosis_l4_l5  right_subarticular_stenosis_l5_s1  \n","0                                0.0                                0.0  \n","1                                1.0                                0.0  \n","2                                0.0                                0.0  \n","3                                0.0                                0.0  \n","4                                1.0                                0.0  \n","\n","[5 rows x 26 columns]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["df_train = pd.read_csv(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train.csv\")\n","\n","# fill missing values with negative so that function can ignore them when calculating the loss and score\n","df_train = df_train.fillna(0)\n","\n","# label encoder df_train\n","labels_encoded = {'Normal/Mild': 0, 'Moderate': 1, 'Severe': 2}\n","for col in df_train:\n","    if col == 'study_id':\n","        df_train['study_id'] = df_train['study_id'].astype(str)\n","    else:\n","        df_train[col] = df_train[col].map(labels_encoded)\n","\n","df_train = df_train.fillna(0)\n","print(df_train.shape)\n","df_train.head(5)"]},{"cell_type":"code","execution_count":22,"metadata":{"_cell_guid":"4a3f3e2b-a145-46e2-83e2-7430827127c6","_uuid":"c6f645a5-ab33-4108-87d7-605d75a48c45","collapsed":false,"execution":{"iopub.execute_input":"2024-10-07T03:37:42.043216Z","iopub.status.busy":"2024-10-07T03:37:42.042870Z","iopub.status.idle":"2024-10-07T03:37:42.267297Z","shell.execute_reply":"2024-10-07T03:37:42.266289Z","shell.execute_reply.started":"2024-10-07T03:37:42.043178Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["df_train_label_coords = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_label_coordinates.csv')\n","\n","# \n","df_train_label_coords.condition = df_train_label_coords.condition.map(lambda x: str.lower(x).replace(' ', '_'))\n","df_train_label_coords.level = df_train_label_coords.level.map(lambda x: str.lower(x).replace('/', '_'))\n","\n","# map series_id to series_desc, then drop series_id\n","dict_series_id_desc = {}\n","for v in metadata_object_train.values():\n","    series = v[\"SeriesInstanceUIDs\"]\n","    series_descs = v[\"SeriesDescriptions\"]\n","    for serie, desc in zip(series, series_descs):\n","        dict_series_id_desc[serie] = desc.replace(' ', '_').replace('/', '_')\n","df_train_label_coords[\"series_desc\"] = df_train_label_coords.series_id.map(dict_series_id_desc).fillna(np.nan)\n","df_train_label_coords = df_train_label_coords.drop('series_id', axis=1)\n","\n","# m_condition\n","df_train_label_coords[\"condition_level\"] = df_train_label_coords[\"condition\"] + '_' + df_train_label_coords[\"level\"]\n","\n","long_df_train = pd.melt(df_train, id_vars=['study_id'], var_name='condition_level', value_name='severity').sort_values(by='study_id')"]},{"cell_type":"code","execution_count":23,"metadata":{"_cell_guid":"7cdb9feb-17af-4498-9815-da858fd1f0cd","_uuid":"eff98876-1d57-46fe-abd9-04d7371279c4","collapsed":false,"execution":{"iopub.execute_input":"2024-10-07T03:37:42.269773Z","iopub.status.busy":"2024-10-07T03:37:42.269430Z","iopub.status.idle":"2024-10-07T03:37:42.274372Z","shell.execute_reply":"2024-10-07T03:37:42.273487Z","shell.execute_reply.started":"2024-10-07T03:37:42.269740Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["CONDITIONS = ['spinal_canal_stenosis', \n","              'left_neural_foraminal_narrowing', 'right_neural_foraminal_narrowing',\n","              'left_subarticular_stenosis', 'right_subarticular_stenosis']\n","\n","LEVELS = ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']"]},{"cell_type":"markdown","metadata":{"_cell_guid":"dd38872c-ec4e-4d35-a745-2654973da0a0","_uuid":"4284707c-f03d-4463-bfc4-837879993378","trusted":true},"source":["# 2. Preprocess png images\n","\n","Unzip output data (png images) from my '/kaggle/input/rsna-making-dataset-png' notebook.\n","\n","**Run the unzip code once!**"]},{"cell_type":"code","execution_count":24,"metadata":{"_cell_guid":"35d48103-ee37-4edc-9e38-a98b0943672f","_uuid":"d2bb0614-f2bd-498b-a50d-b59e973414de","collapsed":false,"execution":{"iopub.execute_input":"2024-10-07T03:37:42.276639Z","iopub.status.busy":"2024-10-07T03:37:42.275754Z","iopub.status.idle":"2024-10-07T03:41:23.275640Z","shell.execute_reply":"2024-10-07T03:41:23.274339Z","shell.execute_reply.started":"2024-10-07T03:37:42.276606Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# run once:\n","!unzip -q /kaggle/input/rsna-making-dataset-png/_output_.zip"]},{"cell_type":"markdown","metadata":{"_cell_guid":"6009f7a1-4667-4da3-a927-80f585532ed0","_uuid":"61f77082-244e-493b-a487-ccc6fcec267d","trusted":true},"source":["# Configs"]},{"cell_type":"code","execution_count":25,"metadata":{"_cell_guid":"5e83ab7b-3e4a-4a0a-b55f-f86dc938a0f0","_uuid":"2e555a5e-605e-468e-843d-43fd65843a82","collapsed":false,"execution":{"iopub.execute_input":"2024-10-07T03:41:23.278011Z","iopub.status.busy":"2024-10-07T03:41:23.277631Z","iopub.status.idle":"2024-10-07T03:41:23.285955Z","shell.execute_reply":"2024-10-07T03:41:23.284900Z","shell.execute_reply.started":"2024-10-07T03:41:23.277973Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"data":{"text/plain":["True"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":26,"metadata":{"_cell_guid":"db959c4f-24af-4b92-87da-874f80073e19","_uuid":"c03c4a5b-c388-4e6c-b4d8-b0a7692e90c3","collapsed":false,"execution":{"iopub.execute_input":"2024-10-07T03:41:23.287814Z","iopub.status.busy":"2024-10-07T03:41:23.287503Z","iopub.status.idle":"2024-10-07T03:41:23.304166Z","shell.execute_reply":"2024-10-07T03:41:23.303307Z","shell.execute_reply.started":"2024-10-07T03:41:23.287780Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["## True -> run normally, False -> debug mode, with lesser computing cost\n","NOT_DEBUG = True\n","\n","OUTPUT_DIR = f'my_results'\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","# set computation device\n","device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n","\n","# parallel processing: no. CPU cores to use for data loading\n","N_WORKERS = os.cpu_count() \n","\n","\n","##########################################\n","########### TRANSFORMATION ###############\n","##########################################\n","\n","# if Automatic Mixed Precision (AMP) is used, \n","# beneficial for certain GPUs like T4 or newer\n","USE_AMP = True\n","SEED = 123\n","\n","# Image configurations\n","IMG_SIZE = [512, 512]\n","IMG_HEIGHT, IMG_WIDTH = 512, 512\n","\n","# # data augmentation:\n","AUG_PROB = 0.75 # probability of applying data aug\n","# # augmentation will be applied to 75% of images during training, improve generalization\n","AUG = True      # whether to use data augmentation\n","\n","\n","####################################\n","############# MODELS ###############\n","####################################\n","\n","# cross-validation:\n","N_FOLDS = 5 if NOT_DEBUG else 2 # use 5 folds in normal mode, 2 in debug mode (faster)\n","\n","# training configs\n","EPOCHS = 5 if NOT_DEBUG else 2\n","\n","# Model I/O\n","IN_CHANS = 30  # no. input channels (typically 1 for grayscale, 3 for RGB)\n","N_LABELS = 25  # no. labels: 3 conditions, 2 has left and right = +1 = (2*2+1) * 5 levels = 25 \n","N_CLASSES = 3 * N_LABELS # classes (for prediction): severity (normal/mid, moderate, severe)\n","# here, labels might be misleading, but they refer to the object/observation\n","# that we want to predict the severity is => classify the condition+level\n","\n","# pretrained, finetuned model name - Efficient Net family of models\n","if NOT_DEBUG:\n","    MODEL_NAME = \"resnet50.a1_in1k\"\n","else:\n","    MODEL_NAME = \"resnet50.a1_in1k\" \n","    # (smaller no. of params)\n","# ns: stands for \"Noisy Student,\" which is a training technique used to improve the model's performance by adding noise to the student model during training.\n","# jft: indicates that the model has been pretrained on the JFT dataset, which is a large dataset developed by Google containing around 300 million images with 18,000 labels.\n","# in1k: indicates that the model has also been fine-tuned or evaluated on the ImageNet-1k dataset, which is a standard benchmark in the field of computer vision containing 1,000 classes.\n","# the names come from timm library\n","\n","\n","###############################\n","########### Tuning ############\n","###############################\n","    \n","# Steps to accumulate gradients before updating the model weights\n","GRAD_ACC = 2 \n","# instead of updating the model weights after every batch, \n","# the gradients are accumulated over several batches (i.e. 2 batches), \n","# and then the model weights are updated once => not increase GPU usage\n","\n","# size = no. of samples in a batch\n","# Target batch size\n","TGT_BATCH_SIZE = 32 # total number of samples you want to process before updating the model weights\n","# Batch size per gradient accumulation step\n","BATCH_SIZE = TGT_BATCH_SIZE // GRAD_ACC  # for now: = 16 samples/batch\n","# This means the model will process 16 samples at a time, \n","# accumulate the gradients, and after processing two such batches (total 32 samples), \n","# it will update the model weights.\n","\n","# maximum norm for gradient clipping => not used\n","MAX_GRAD_NORM = None\n","# Gradient clipping is a technique to prevent the exploding gradient problem \n","# by capping (clipping) the gradients during backpropagation to a maximum norm.\n","# but if not used, no need to stablize when computed gradient norm exceeds some number\n","\n","# no. epochs with no improvement after which training will be stopped early\n","EARLY_STOPPING_EPOCH = 3\n","\n","# learning rate (base = 2e-4), but adjusted based on the batch size\n","LR = 2e-4 * TGT_BATCH_SIZE / 32   # commonly start at 2e-4\n","# adjustment is needed b/c, in a case that needs a larger batch size \n","# => each training step updates the  model with more data \n","# => gradient estimates are more accurate => LR is scaled up proportionally\n","\n","# weight decay for regularization => to prevent overfitting (= decrease variance)\n","# penalize large weights in model, introduce more bias, and aim for more generalizble\n","# also not rely too much on any particular weight, promote more evenly distributed weights\n","# in the loss function => reduce weight vector towards 0 when backprop\n","# example like squared L2 norm of the weights\n","WD = 1e-2 # commonly used starting point in practice\n","# example: optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WD)\n","\n","\n","###############################\n","########## SEEDS ##############\n","###############################\n","def set_random_seed(seed, deterministic: bool = False):\n","    \"\"\"Set seeds for all packages needed\"\"\"\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    # for hash-based randomization in Python operations like dictionary keys:\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    # PyTorch’s CPU-based random number generator:\n","    # torch.manual_seed(seed) \n","    # PyTorch’s GPU-based random number generator:\n","    # torch.cuda.manual_seed(seed)  # type: ignore\n","    \n","    # enables the cuDNN auto-tuner to find the best algorithms for hardware\n","    # speed up training on GPUs by optimizing performance => require deterministic\n","    torch.backends.cudnn.benchmark = True\n","    # cuDNN should use deterministic algorithms for convolutions\n","    torch.backends.cudnn.deterministic = deterministic  # make sure no deterministic behaviors\n","    # non-deterministic in this case b/c want to avoid performance or memory issue\n","    # due to the use of less optimized, deterministic algo (when search for one in\n","    # benchmark)\n","    \n","set_random_seed(SEED)"]},{"cell_type":"markdown","metadata":{"_cell_guid":"272dda0e-bd17-493e-ab01-132710a0ec92","_uuid":"386eb7e2-c5db-461c-9aaf-d6542f913328","trusted":true},"source":["# 3. Define Dataset + Transforms + DataLoader\n","\n","https://pytorch.org/tutorials/recipes/recipes/custom_dataset_transforms_loader.html"]},{"cell_type":"code","execution_count":27,"metadata":{"_cell_guid":"cabca976-e070-4478-b17d-29708d59f7b2","_uuid":"71ee46e8-eba0-40c5-b761-2b59337c174f","collapsed":false,"execution":{"iopub.execute_input":"2024-10-07T03:41:23.305580Z","iopub.status.busy":"2024-10-07T03:41:23.305240Z","iopub.status.idle":"2024-10-07T03:41:23.319297Z","shell.execute_reply":"2024-10-07T03:41:23.318209Z","shell.execute_reply.started":"2024-10-07T03:41:23.305547Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"data":{"text/plain":["<contextlib.ExitStack at 0x7ee1866e0520>"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["from __future__ import print_function, division\n","import os\n","import torch\n","import pandas as pd\n","from skimage import io, transform\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","import random\n","\n","# Ignore warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","plt.ion()   # interactive mode"]},{"cell_type":"code","execution_count":28,"metadata":{"_cell_guid":"ade7c35c-b8ed-4388-9fe8-f9d8848e6a69","_uuid":"ac6ade4d-a3d3-4bb4-adcc-d4bfbc216b5c","collapsed":false,"execution":{"iopub.execute_input":"2024-10-07T03:41:23.321142Z","iopub.status.busy":"2024-10-07T03:41:23.320832Z","iopub.status.idle":"2024-10-07T03:41:23.336844Z","shell.execute_reply":"2024-10-07T03:41:23.335968Z","shell.execute_reply.started":"2024-10-07T03:41:23.321100Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class LumbarDataset(Dataset):\n","    \n","    \"\"\"Lumbar Degenerative Conditions dataset.\"\"\"\n","\n","    def __init__(self, df, transform=None, phase='train'):\n","        self.df = df\n","        self.transform = transform # from PyTorch data class and transforms torchvision library\n","        self.phase = phase\n","    \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def _load_image(self, folder_path, file_name):\n","        \"\"\"\n","        loads and converts a single image to grayscale and numpy.\n","        \"\"\"\n","        try:\n","            img_path = os.path.join(folder_path, file_name)\n","            img = Image.open(img_path).convert('L')  # grayscale\n","            img_np = np.array(img, dtype=np.uint8)  # convert to numpy array\n","            return img_np\n","        except Exception as e:\n","            print(f\"error loading image: {img_path}, {str(e)}\")\n","            return np.zeros(self.img_size, dtype=np.uint8)  # return blank image on error\n","    \n","    # tough one:\n","    def __getitem__(self, idx_in_train_df):\n","        \"\"\"\n","        get images given idx_in_train_df\n","        \"\"\"\n","        \n","        # each study_id has 30 images/channels, each image is 512x512 on top of each other (assuming grayscale!)\n","        stack_2d_images = np.zeros((512, 512, IN_CHANS), dtype=np.uint8) # placeholder for image data, \n","        # so later we can populate it with images from 3 methods!\n","        # stack_2d_images[512, 512, 0] would be img1\n","        # stack_2d_images[512, 512, 1] would be img2\n","        # the ... reference the entire 512 x 512 image in the i-th channel\n","        \n","        # rmb: df here is the train_df (not the one combined with coord)\n","        # for each specific study_id\n","        row = self.df.iloc[idx_in_train_df]\n","        study_id = int(row['study_id'])\n","        # numpy array consisted of all the labels for all the conditions for this study_id:\n","        conditions_levels = row[1:].values.astype(np.int8) \n","        \n","        # get folder\n","        folder_Sagittal_T1 = f'./train_images_png/{study_id}/Sagittal_T1/'\n","        folder_Sagittal_T2_STIR = f'./train_images_png/{study_id}/Sagittal_T2_STIR/'\n","        folder_Axial_T2 = f'./train_images_png/{study_id}/Axial_T2/'\n","        \n","        base_path = f'./train_images_png/{study_id}'\n","        \n","        # Sagittal T1\n","        try:\n","            for i, fname in enumerate(os.listdir(folder_Sagittal_T1)):\n","                img_np = self._load_image(folder_Sagittal_T1, fname)\n","                stack_2d_images[..., i] = img_np.astype(np.uint8)  # first ten channels/layers in stack_2d_images\n","        except:\n","            pass\n","            \n","        # Sagittal T2_STIR\n","        try:\n","            for i, fname in enumerate(os.listdir(folder_Sagittal_T2_STIR)):\n","                img_np = self._load_image(folder_Sagittal_T2_STIR, fname)\n","                stack_2d_images[..., i+10] = img_np.astype(np.uint8) # next ten channels/layers in stack_2d_images\n","        except:\n","            pass\n","            \n","            \n","        # Axial T2\n","        # select random 10 images from Axial T2\n","        try:\n","            axial_fnames = random.sample(os.listdir(folder_Axial_T2), 10)\n","            for i, fname in enumerate(axial_fnames):\n","                img_np = self._load_image(folder_Axial_T2, fname)\n","                stack_2d_images[..., i+20] = img_np.astype(np.uint8) # last ten channels/layers in stack_2d_images \n","        except:\n","            pass\n","            \n","        # print(\"shape of the image stack:\", stack_2d_images.shape)  # 512, 521, 30\n","            \n","        # transforms\n","        # transforms if given the transform functions are provided to do so\n","        if self.transform is not None:\n","            stack_2d_images = self.transform(image=stack_2d_images)['image']\n","\n","        # transpose the stack from (height, width, channel) into (channels, height, width)\n","        stack_2d_images = stack_2d_images.transpose(2, 0, 1)\n","        \n","        # lastly, for this study_id, we get:\n","        return stack_2d_images, conditions_levels"]},{"cell_type":"markdown","metadata":{"_cell_guid":"13952db3-b680-49b2-b445-92daaf306a89","_uuid":"560d2ff2-6ebe-46fb-b1de-239315a66ae7","trusted":true},"source":["The data augmentation code is from this brilliant [notebook](https://www.kaggle.com/code/haqishen/1st-place-soluiton-code-small-ver). The notebook also works on diagnosis medical images."]},{"cell_type":"code","execution_count":29,"metadata":{"_cell_guid":"af1f91aa-b607-4ec4-ba6d-f14dba1ad643","_uuid":"b45a8c76-54fe-4437-9d6c-b97a28fcbb4b","collapsed":false,"execution":{"iopub.execute_input":"2024-10-07T03:41:23.341092Z","iopub.status.busy":"2024-10-07T03:41:23.340673Z","iopub.status.idle":"2024-10-07T03:41:23.358105Z","shell.execute_reply":"2024-10-07T03:41:23.357252Z","shell.execute_reply.started":"2024-10-07T03:41:23.341043Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import albumentations as A\n","\n","transforms_train = A.Compose([\n","    # A.Transpose(p=0.5),\n","    # A.VerticalFlip(p=0.5),\n","    # A.HorizontalFlip(p=0.5),\n","    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.7),\n","    A.OneOf([\n","        A.MotionBlur(blur_limit=5),\n","        A.MedianBlur(blur_limit=5),\n","        A.GaussianBlur(blur_limit=5),\n","        A.GaussNoise(var_limit=(5.0, 30.0)),\n","    ], p=0.7),\n","\n","    A.OneOf([\n","        A.OpticalDistortion(distort_limit=1.0),\n","        A.GridDistortion(num_steps=5, distort_limit=1.),\n","        A.ElasticTransform(alpha=3),\n","    ], p=0.7),\n","\n","    # A.CLAHE(clip_limit=4.0, p=0.7),\n","    # A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5),\n","    \n","    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.7),\n","    A.Resize(IMG_HEIGHT, IMG_WIDTH),\n","    \n","    # replace Cutout with CoarseDropout\n","    A.CoarseDropout(max_holes=16, max_height=64, max_width=64, min_holes=1, min_height=8, min_width=8, p=0.7),    \n","    A.Normalize(mean=0.5, std=0.5) # >??\n","])\n","\n","transforms_val = A.Compose([\n","    A.Resize(IMG_HEIGHT, IMG_WIDTH),\n","    A.Normalize(mean=0.5, std=0.5)\n","])\n","\n","if not NOT_DEBUG or not AUG:\n","    transforms_train = transforms_val"]},{"cell_type":"code","execution_count":30,"metadata":{"_cell_guid":"6fb93fcf-7722-4b81-ad29-0e76fe825ad1","_uuid":"1040b0fa-69fb-472e-9b9f-f47a46a7cec5","collapsed":false,"execution":{"iopub.execute_input":"2024-10-07T03:41:23.359591Z","iopub.status.busy":"2024-10-07T03:41:23.359241Z","iopub.status.idle":"2024-10-07T03:41:23.369918Z","shell.execute_reply":"2024-10-07T03:41:23.369006Z","shell.execute_reply.started":"2024-10-07T03:41:23.359560Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# train_data = LumbarDataset(df_train, phase='train', transform=transforms_train)\n","# for idx, (stack, conditions_labels) in zip(range(5), train_data):\n","#     print(f\"id in df_train: {idx}\")\n","#     print(f\"conditions and labels: {conditions_labels, conditions_labels.shape}\")\n","#     print(f\"stack 2D images for this id\")\n","#     print(f\"stack shape: {stack.shape}\")\n","#     img_displayable = stack.transpose(0,2,3,1)[0, :, :, :3]\n","#     # to display image, from (1, channel, height, width) into (1, height, width, channel)\n","#     # then pick the first image in the stack \n","#     # [0, :, :, :3] = [first_image, all values for height, all values for width, first 3 channels RGB of the image]\n","#     # if [0,512,512,3] is trying to select a specific position within the array. Specifically, trying to index at position 0 in the first dimension, 512 in the second dimension, 512 in the third dimension, and 3 in the fourth dimension\n","#     img_displayable = (img_displayable + 1) / 2\n","#     plt.imshow(img_displayable)\n","#     plt.show()\n","#     print()\n","    \n","# plt.close()"]},{"cell_type":"markdown","metadata":{"_cell_guid":"413bc2e6-115a-4075-bdd7-1e7e388b82d3","_uuid":"80f0e4a8-95f4-40a2-8fee-f0cdf76daf38","trusted":true},"source":["# 4. Define Model + Training"]},{"cell_type":"code","execution_count":31,"metadata":{"_cell_guid":"6fe93be3-6ab5-40c7-8090-56941e3516ec","_uuid":"fd8929c8-69fc-4a8d-9620-34df49f67e35","collapsed":false,"execution":{"iopub.execute_input":"2024-10-07T03:41:23.371281Z","iopub.status.busy":"2024-10-07T03:41:23.370996Z","iopub.status.idle":"2024-10-07T03:41:23.386517Z","shell.execute_reply":"2024-10-07T03:41:23.385581Z","shell.execute_reply.started":"2024-10-07T03:41:23.371252Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import timm # pretrained models!\n","\n","RESNET50_MODEL_NAME = \"resnet50\"\n","NO_CLASSES = 75 # 5 conditions x 5 levels x 3 severity"]},{"cell_type":"code","execution_count":32,"metadata":{"_cell_guid":"230d762e-04cb-42d1-8671-51a586327f0f","_uuid":"33d4d5fc-5bfe-4460-8ff4-697ddb77425d","collapsed":false,"execution":{"iopub.execute_input":"2024-10-07T03:41:23.387822Z","iopub.status.busy":"2024-10-07T03:41:23.387526Z","iopub.status.idle":"2024-10-07T03:41:23.396817Z","shell.execute_reply":"2024-10-07T03:41:23.395985Z","shell.execute_reply.started":"2024-10-07T03:41:23.387792Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import timm\n","\n","class BuildModel(nn.Module):\n","    def __init__(self, model, \n","                 in_c=30, no_conditions_labels=NO_CLASSES,  # 75\n","                 pretrained=True, features_only=False):\n","        \n","        super(BuildModel, self).__init__()\n","        \n","        # Create the model with specified parameters\n","        self.model = timm.create_model(model,\n","                                        pretrained=pretrained,\n","                                        features_only=features_only,\n","                                        in_chans=in_c,\n","                                        num_classes=no_conditions_labels,\n","                                        global_pool='avg')\n","\n","    def forward(self, x):\n","        y = self.model(x)\n","        return y\n","\n","    # no backward! because use pretrained parameters"]},{"cell_type":"code","execution_count":33,"metadata":{"_cell_guid":"ee818308-455c-4292-a828-9402d969247b","_uuid":"1ab64015-9b9b-4bbe-a211-968ce492bb3a","collapsed":false,"execution":{"iopub.execute_input":"2024-10-07T03:41:23.398253Z","iopub.status.busy":"2024-10-07T03:41:23.397962Z","iopub.status.idle":"2024-10-07T03:41:25.344289Z","shell.execute_reply":"2024-10-07T03:41:25.343328Z","shell.execute_reply.started":"2024-10-07T03:41:23.398223Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"data":{"text/plain":["(torch.Size([2, 75]),\n"," tensor([[0.0156, 0.0098, 0.0123, 0.0133, 0.0201, 0.0132, 0.0128, 0.0131, 0.0141,\n","          0.0112, 0.0114, 0.0120, 0.0135, 0.0142, 0.0139, 0.0167, 0.0090, 0.0114,\n","          0.0287, 0.0130, 0.0087, 0.0176, 0.0170, 0.0117, 0.0102, 0.0098, 0.0239,\n","          0.0173, 0.0097, 0.0114, 0.0089, 0.0132, 0.0097, 0.0167, 0.0150, 0.0135,\n","          0.0145, 0.0085, 0.0096, 0.0172, 0.0105, 0.0125, 0.0087, 0.0114, 0.0148,\n","          0.0116, 0.0158, 0.0172, 0.0132, 0.0169, 0.0115, 0.0147, 0.0181, 0.0095,\n","          0.0115, 0.0131, 0.0154, 0.0111, 0.0129, 0.0117, 0.0117, 0.0185, 0.0173,\n","          0.0112, 0.0138, 0.0139, 0.0117, 0.0128, 0.0119, 0.0109, 0.0129, 0.0121,\n","          0.0128, 0.0113, 0.0113],\n","         [0.0154, 0.0098, 0.0120, 0.0136, 0.0203, 0.0130, 0.0124, 0.0130, 0.0142,\n","          0.0118, 0.0120, 0.0127, 0.0146, 0.0144, 0.0136, 0.0165, 0.0095, 0.0112,\n","          0.0276, 0.0133, 0.0088, 0.0176, 0.0177, 0.0111, 0.0103, 0.0100, 0.0241,\n","          0.0177, 0.0096, 0.0116, 0.0085, 0.0127, 0.0098, 0.0164, 0.0145, 0.0137,\n","          0.0145, 0.0088, 0.0095, 0.0169, 0.0103, 0.0128, 0.0086, 0.0115, 0.0147,\n","          0.0115, 0.0156, 0.0174, 0.0131, 0.0164, 0.0119, 0.0145, 0.0174, 0.0098,\n","          0.0118, 0.0131, 0.0159, 0.0112, 0.0124, 0.0113, 0.0114, 0.0185, 0.0175,\n","          0.0109, 0.0137, 0.0147, 0.0115, 0.0123, 0.0121, 0.0109, 0.0125, 0.0119,\n","          0.0127, 0.0114, 0.0125]], grad_fn=<SoftmaxBackward0>))"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["model_draft = BuildModel(\"resnet50\", pretrained=False)\n","random_input = torch.randn(2, 30, 512, 512)\n","pred_prob = model_draft(random_input)\n","probabilities = F.softmax(pred_prob, dim=1)\n","pred_prob.shape, probabilities"]},{"cell_type":"markdown","metadata":{"_cell_guid":"be3fdef7-dd6a-4885-a78b-6a91b36a8d1f","_uuid":"033fabc8-3cf7-4d03-949d-755e927e80b0","trusted":true},"source":["Training"]},{"cell_type":"code","execution_count":34,"metadata":{"_cell_guid":"67536ef2-f6df-4412-a3dd-d6ba34eba48e","_uuid":"95f2b611-ccc8-4fe6-8663-0c8cf1bb22ed","collapsed":false,"execution":{"iopub.execute_input":"2024-10-07T03:41:25.345996Z","iopub.status.busy":"2024-10-07T03:41:25.345662Z","iopub.status.idle":"2024-10-07T03:41:25.351007Z","shell.execute_reply":"2024-10-07T03:41:25.349993Z","shell.execute_reply.started":"2024-10-07T03:41:25.345962Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["from collections import OrderedDict\n","from tqdm import tqdm\n","import math\n","from glob import glob\n","\n","from sklearn.model_selection import KFold\n","from torch.optim import AdamW # optimizer for deep learning, more details to learn\n","from transformers import get_cosine_schedule_with_warmup # improve convergence, details to learn"]},{"cell_type":"code","execution_count":35,"metadata":{"_cell_guid":"3487fd4d-d5b9-4c10-84bc-8082484289f7","_uuid":"63bd25cb-87fe-4f53-86ac-7197b8c6d34e","collapsed":false,"execution":{"iopub.execute_input":"2024-10-07T03:41:25.352505Z","iopub.status.busy":"2024-10-07T03:41:25.352172Z","iopub.status.idle":"2024-10-07T03:41:26.391140Z","shell.execute_reply":"2024-10-07T03:41:26.390081Z","shell.execute_reply.started":"2024-10-07T03:41:25.352469Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["train_data = LumbarDataset(df_train, phase='train', transform=transforms_train)\n","train_loader = DataLoader(\n","                        train_data,  \n","                        batch_size=1,        # no. samples to load in each batch\n","                        shuffle=False,       # no shuffle\n","                        pin_memory=True,     # copy tensors into CUDA pinned memory\n","                        drop_last=False,     # drop the last incomplete batch\n","                        num_workers=0        # no parallel subprocesses \n","                        )"]},{"cell_type":"code","execution_count":36,"metadata":{"_cell_guid":"474030c2-5d2f-4dbc-aaae-1ff423a2a55a","_uuid":"06c2838f-3eee-4eaa-a810-b1cff8d51905","collapsed":false,"execution":{"iopub.execute_input":"2024-10-07T03:41:26.393314Z","iopub.status.busy":"2024-10-07T03:41:26.392771Z","iopub.status.idle":"2024-10-07T04:15:11.771230Z","shell.execute_reply":"2024-10-07T04:15:11.769823Z","shell.execute_reply.started":"2024-10-07T03:41:26.393279Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Starting epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 123/123 [06:58<00:00,  3.41s/it, loss=0.730773]\n"]},{"name":"stdout","output_type":"stream","text":["Training Loss: 0.918495\n","Epoch 1: Best loss updated from inf to 0.918495\n","Starting epoch 2\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 123/123 [06:43<00:00,  3.28s/it, loss=0.680334]\n"]},{"name":"stdout","output_type":"stream","text":["Training Loss: 0.772411\n","Epoch 2: Best loss updated from 0.918495 to 0.772411\n","Starting epoch 3\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 123/123 [06:36<00:00,  3.23s/it, loss=0.698507]\n"]},{"name":"stdout","output_type":"stream","text":["Training Loss: 0.746528\n","Epoch 3: Best loss updated from 0.772411 to 0.746528\n","Starting epoch 4\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 123/123 [06:45<00:00,  3.29s/it, loss=0.809720]\n"]},{"name":"stdout","output_type":"stream","text":["Training Loss: 0.735933\n","Epoch 4: Best loss updated from 0.746528 to 0.735933\n","Starting epoch 5\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 123/123 [06:37<00:00,  3.23s/it, loss=0.770923]\n"]},{"name":"stdout","output_type":"stream","text":["Training Loss: 0.730947\n","Epoch 5: Best loss updated from 0.735933 to 0.730947\n","Training complete.\n"]}],"source":["autocast = torch.cuda.amp.autocast(enabled=USE_AMP, dtype=torch.half)\n","scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP, init_scale=4096)\n","\n","df_train = df_train.copy() # since we want validation inside training too \n","\n","train_ds = LumbarDataset(df_train, phase='train', transform=transforms_train)\n","train_dl = DataLoader(\n","    train_ds,\n","    batch_size=BATCH_SIZE,\n","    shuffle=True,\n","    pin_memory=True,\n","    drop_last=True,\n","    num_workers=N_WORKERS\n",")\n","\n","# intialize model, optimizer, and loss function\n","model = BuildModel(\"resnet50\", IN_CHANS, N_CLASSES, pretrained=True)\n","model.to(device)\n","\n","optimizer = AdamW(model.parameters(), lr=LR, weight_decay=WD)\n","\n","# scheduler settings\n","warmup_steps = EPOCHS / 10 * len(train_dl) // GRAD_ACC\n","num_total_steps = EPOCHS * len(train_dl) // GRAD_ACC\n","num_cycles = 0.475\n","scheduler = get_cosine_schedule_with_warmup(optimizer,\n","                                             num_warmup_steps=warmup_steps,\n","                                             num_training_steps=num_total_steps,\n","                                             num_cycles=num_cycles)\n","\n","# Loss function\n","weights = torch.tensor([1.0, 2.0, 4.0])  # Adjust based on your dataset\n","criterion = nn.CrossEntropyLoss(weight=weights.to(device))\n","\n","# Training loop\n","best_loss = float('inf')  # Set best loss to infinity initially\n","es_step = 0\n","\n","for epoch in range(1, EPOCHS + 1):\n","    print(f'Starting epoch {epoch}')\n","    model.train()\n","    total_loss = 0\n","\n","    with tqdm(train_dl, leave=True) as pbar:\n","        optimizer.zero_grad()\n","        for idx, (x, t) in enumerate(pbar):\n","            x = x.to(device)\n","            t = t.to(device)\n","            \n","#             print(\"x: \", x)\n","#             print(\"t: \", t)\n","\n","            with autocast:\n","                loss = 0\n","                y = model(x)\n","#                print(y)\n","                for col in range(N_LABELS):\n","                    pred = y[:, col * 3:col * 3 + 3]\n","                    gt = t[:, col].long() \n","\n","#                     print(\"target values:\", gt)\n","#                     print(\"predictions shape:\", pred.shape)\n","\n","                    loss += criterion(pred, gt) / N_LABELS\n","\n","                total_loss += loss.item()\n","                if GRAD_ACC > 1:\n","                    loss /= GRAD_ACC\n","\n","            if not math.isfinite(loss):\n","                print(f\"Loss is {loss}, stopping training\")\n","                sys.exit(1)\n","\n","            pbar.set_postfix(loss=f'{loss.item() * GRAD_ACC:.6f}')\n","            scaler.scale(loss).backward()\n","\n","            # Gradient clipping\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM or 1e9)\n","\n","            if (idx + 1) % GRAD_ACC == 0:\n","                scaler.step(optimizer)\n","                scaler.update()\n","                optimizer.zero_grad()\n","                if scheduler is not None:\n","                    scheduler.step()\n","\n","    train_loss = total_loss / len(train_dl)\n","    print(f'Training Loss: {train_loss:.6f}')\n","\n","\n","    if train_loss < best_loss:\n","        print(f'Epoch {epoch}: Best loss updated from {best_loss:.6f} to {train_loss:.6f}')\n","        best_loss = train_loss\n","        fname = f'{OUTPUT_DIR}/best_model.pt'\n","        torch.save(model.state_dict(), fname)\n","\n","print('Training complete.')"]},{"cell_type":"markdown","metadata":{"_cell_guid":"1585c5ae-5711-4a4d-bd92-e34379d56023","_uuid":"6dac2760-62c2-45fa-ba22-0660cb4be260","trusted":true},"source":["# 5. Test images\n","\n","The new test data class processing is taken/modified based on this notebook: https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-submission-baseline"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-10-07T04:15:11.774051Z","iopub.status.busy":"2024-10-07T04:15:11.773619Z","iopub.status.idle":"2024-10-07T04:15:11.780540Z","shell.execute_reply":"2024-10-07T04:15:11.779499Z","shell.execute_reply.started":"2024-10-07T04:15:11.774003Z"},"trusted":true},"outputs":[],"source":["rd = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'\n","\n","def atoi(text):\n","    return int(text) if text.isdigit() else text\n","\n","def natural_keys(text):\n","    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]\n","\n","import glob\n","import re"]},{"cell_type":"code","execution_count":38,"metadata":{"_cell_guid":"1ec45789-b7da-4381-8b4f-2664922ad826","_uuid":"bb768e84-7d21-4dba-83c6-399c6984e3a4","collapsed":false,"execution":{"iopub.execute_input":"2024-10-07T04:15:11.782182Z","iopub.status.busy":"2024-10-07T04:15:11.781851Z","iopub.status.idle":"2024-10-07T04:15:11.827539Z","shell.execute_reply":"2024-10-07T04:15:11.826619Z","shell.execute_reply.started":"2024-10-07T04:15:11.782142Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class RSNA24TestDataset(Dataset):\n","    def __init__(self, df, study_ids, phase='test', transform=None):\n","        self.df = df\n","        self.study_ids = study_ids\n","        self.transform = transform\n","        self.phase = phase\n","    \n","    def __len__(self):\n","        return len(self.study_ids)\n","    \n","    def get_img_paths(self, study_id, series_desc):\n","        pdf = self.df[self.df['study_id']==study_id]\n","        pdf_ = pdf[pdf['series_description']==series_desc]\n","        allimgs = []\n","        for i, row in pdf_.iterrows():\n","            pimgs = glob.glob(f'{rd}/test_images/{study_id}/{row[\"series_id\"]}/*.dcm')\n","            pimgs = sorted(pimgs, key=natural_keys)\n","            allimgs.extend(pimgs)\n","            \n","        return allimgs\n","    \n","    def read_dcm_ret_arr(self, src_path):\n","        dicom_data = pydicom.dcmread(src_path)\n","        image = dicom_data.pixel_array\n","        image = (image - image.min()) / (image.max() - image.min() + 1e-6) * 255\n","        img = cv2.resize(image, (IMG_SIZE[0], IMG_SIZE[1]),interpolation=cv2.INTER_CUBIC)\n","        assert img.shape==(IMG_SIZE[0], IMG_SIZE[1])\n","        return img\n","\n","    def __getitem__(self, idx):\n","        x = np.zeros((IMG_SIZE[0], IMG_SIZE[1], IN_CHANS), dtype=np.uint8)\n","        st_id = self.study_ids[idx]        \n","        \n","        # Sagittal T1\n","        allimgs_st1 = self.get_img_paths(st_id, 'Sagittal T1')\n","        if len(allimgs_st1)==0:\n","            print(st_id, ': Sagittal T1, has no images')\n","        \n","        else:\n","            step = len(allimgs_st1) / 10.0\n","            st = len(allimgs_st1)/2.0 - 4.0*step\n","            end = len(allimgs_st1)+0.0001\n","            for j, i in enumerate(np.arange(st, end, step)):\n","                try:\n","                    ind2 = max(0, int((i-0.5001).round()))\n","                    img = self.read_dcm_ret_arr(allimgs_st1[ind2])\n","                    x[..., j] = img.astype(np.uint8)\n","                except:\n","                    print(f'failed to load on {st_id}, Sagittal T1')\n","                    pass\n","            \n","        # Sagittal T2/STIR\n","        allimgs_st2 = self.get_img_paths(st_id, 'Sagittal T2/STIR')\n","        if len(allimgs_st2)==0:\n","            print(st_id, ': Sagittal T2/STIR, has no images')\n","            \n","        else:\n","            step = len(allimgs_st2) / 10.0\n","            st = len(allimgs_st2)/2.0 - 4.0*step\n","            end = len(allimgs_st2)+0.0001\n","            for j, i in enumerate(np.arange(st, end, step)):\n","                try:\n","                    ind2 = max(0, int((i-0.5001).round()))\n","                    img = self.read_dcm_ret_arr(allimgs_st2[ind2])\n","                    x[..., j+10] = img.astype(np.uint8)\n","                except:\n","                    print(f'failed to load on {st_id}, Sagittal T2/STIR')\n","                    pass\n","            \n","        # Axial T2\n","        allimgs_at2 = self.get_img_paths(st_id, 'Axial T2')\n","        if len(allimgs_at2)==0:\n","            print(st_id, ': Axial T2, has no images')\n","            \n","        else:\n","            step = len(allimgs_at2) / 10.0\n","            st = len(allimgs_at2)/2.0 - 4.0*step\n","            end = len(allimgs_at2)+0.0001\n","\n","            for j, i in enumerate(np.arange(st, end, step)):\n","                try:\n","                    ind2 = max(0, int((i-0.5001).round()))\n","                    img = self.read_dcm_ret_arr(allimgs_at2[ind2])\n","                    x[..., j+20] = img.astype(np.uint8)\n","                except:\n","                    print(f'failed to load on {st_id}, Axial T2')\n","                    pass  \n","            \n","            \n","        if self.transform is not None:\n","            x = self.transform(image=x)['image']\n","\n","        x = x.transpose(2, 0, 1)\n","                \n","        return x, str(st_id)\n","    \n","transforms_test = A.Compose([\n","    A.Resize(IMG_SIZE[0], IMG_SIZE[1]),\n","    A.Normalize(mean=0.5, std=0.5)\n","])\n","\n","df_test = pd.read_csv(f'/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_series_descriptions.csv')\n","study_ids_test = list(df_test['study_id'].unique())\n","\n","test_ds = RSNA24TestDataset(df_test, study_ids_test, transform=transforms_test)\n","test_dl = DataLoader(\n","    test_ds, \n","    batch_size=1, \n","    shuffle=False,\n","    num_workers=N_WORKERS,\n","    pin_memory=True,\n","    drop_last=False\n",")"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-10-07T04:15:11.830606Z","iopub.status.busy":"2024-10-07T04:15:11.828764Z","iopub.status.idle":"2024-10-07T04:15:11.841814Z","shell.execute_reply":"2024-10-07T04:15:11.840891Z","shell.execute_reply.started":"2024-10-07T04:15:11.830573Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['normal_mild', 'moderate', 'severe']"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["sample_sub = pd.read_csv(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/sample_submission.csv\")\n","LABELS = list(sample_sub.columns[1:])\n","LABELS"]},{"cell_type":"code","execution_count":40,"metadata":{"_cell_guid":"c142617f-c353-485a-9b40-00d6ab1c2e70","_uuid":"019eb5ce-0bfd-4a59-a4a0-070acf3c44e2","execution":{"iopub.execute_input":"2024-10-07T04:15:11.843540Z","iopub.status.busy":"2024-10-07T04:15:11.843156Z","iopub.status.idle":"2024-10-07T04:15:12.472444Z","shell.execute_reply":"2024-10-07T04:15:12.471169Z","shell.execute_reply.started":"2024-10-07T04:15:11.843498Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading model from my_results/best_model.pt...\n"]},{"data":{"text/plain":["RSNA24Model(\n","  (model): ResNet(\n","    (conv1): Conv2d(30, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (act1): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","      (4): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","      (5): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop_block): Identity()\n","        (act2): ReLU(inplace=True)\n","        (aa): Identity()\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","    )\n","    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n","    (fc): Linear(in_features=2048, out_features=75, bias=True)\n","  )\n",")"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["class RSNA24Model(nn.Module):\n","    def __init__(self, model_name, in_c=30, n_classes=75, pretrained=True, features_only=False):\n","        super().__init__()\n","        self.model = timm.create_model(\n","                                    model_name,\n","                                    pretrained=pretrained, \n","                                    features_only=features_only,\n","                                    in_chans=in_c,\n","                                    num_classes=n_classes,\n","                                    global_pool='avg'\n","                                    )\n","    \n","    def forward(self, x):\n","        y = self.model(x)\n","        return y\n","\n","# get the trained model with learned parameters\n","model_path = f'{OUTPUT_DIR}/best_model.pt'  \n","print(f'Loading model from {model_path}...')\n","model = RSNA24Model(\"resnet50\", IN_CHANS, N_CLASSES, pretrained=False)\n","model.load_state_dict(torch.load(model_path))\n","model.eval()\n","model.half()  \n","model.to(device)"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-10-07T04:15:12.474305Z","iopub.status.busy":"2024-10-07T04:15:12.473900Z","iopub.status.idle":"2024-10-07T04:15:14.477873Z","shell.execute_reply":"2024-10-07T04:15:14.476744Z","shell.execute_reply.started":"2024-10-07T04:15:12.474261Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:01<00:00,  1.99s/it]\n"]}],"source":["autocast = torch.cuda.amp.autocast(enabled=USE_AMP, dtype=torch.half)\n","y_preds = []\n","row_names = []\n","\n","with tqdm(test_dl, leave=True) as pbar:\n","    with torch.no_grad():\n","        for idx, (x, si) in enumerate(pbar):\n","            x = x.to(device)\n","            pred_per_study = np.zeros((25, 3))\n","            \n","            for cond in CONDITIONS:\n","                for level in LEVELS:\n","                    row_names.append(si[0] + '_' + cond + '_' + level)\n","            \n","            with autocast:\n","                y = model(x)[0]\n","                for col in range(N_LABELS):\n","                    pred = y[col*3:col*3+3]\n","                    y_pred = pred.float().softmax(0).cpu().numpy()\n","                    pred_per_study[col] += y_pred \n","                y_preds.append(pred_per_study)\n","\n"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-10-07T04:47:20.221171Z","iopub.status.busy":"2024-10-07T04:47:20.220298Z","iopub.status.idle":"2024-10-07T04:47:20.239632Z","shell.execute_reply":"2024-10-07T04:47:20.238723Z","shell.execute_reply.started":"2024-10-07T04:47:20.221126Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>row_id</th>\n","      <th>normal_mild</th>\n","      <th>moderate</th>\n","      <th>severe</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>44036939_spinal_canal_stenosis_l1_l2</td>\n","      <td>0.555168</td>\n","      <td>0.237786</td>\n","      <td>0.207046</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>44036939_spinal_canal_stenosis_l2_l3</td>\n","      <td>0.449050</td>\n","      <td>0.303324</td>\n","      <td>0.247626</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>44036939_spinal_canal_stenosis_l3_l4</td>\n","      <td>0.371784</td>\n","      <td>0.321507</td>\n","      <td>0.306709</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>44036939_spinal_canal_stenosis_l4_l5</td>\n","      <td>0.316991</td>\n","      <td>0.285000</td>\n","      <td>0.398009</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>44036939_spinal_canal_stenosis_l5_s1</td>\n","      <td>0.557710</td>\n","      <td>0.229779</td>\n","      <td>0.212511</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                 row_id  normal_mild  moderate    severe\n","0  44036939_spinal_canal_stenosis_l1_l2     0.555168  0.237786  0.207046\n","1  44036939_spinal_canal_stenosis_l2_l3     0.449050  0.303324  0.247626\n","2  44036939_spinal_canal_stenosis_l3_l4     0.371784  0.321507  0.306709\n","3  44036939_spinal_canal_stenosis_l4_l5     0.316991  0.285000  0.398009\n","4  44036939_spinal_canal_stenosis_l5_s1     0.557710  0.229779  0.212511"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["sub = pd.DataFrame()\n","sub['row_id'] = row_names\n","sub[LABELS] = y_preds[0]  \n","\n","sub.to_csv('submission.csv', index=False)\n","pd.read_csv('submission.csv').head()"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":8561470,"sourceId":71549,"sourceType":"competition"},{"sourceId":188607170,"sourceType":"kernelVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
